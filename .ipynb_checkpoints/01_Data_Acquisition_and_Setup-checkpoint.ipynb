{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffdd8ed-fba6-4030-a494-1d55684789cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10179 daily rows to data/raw\\weather_historical.csv\n"
     ]
    }
   ],
   "source": [
    "# weather_fetch_safe.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "API_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "LATITUDE = 5.3173\n",
    "LONGITUDE = 75.7139\n",
    "OUT_DIR = \"data/raw\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_CSV = os.path.join(OUT_DIR, \"weather_historical.csv\")\n",
    "\n",
    "# Choose your date range (note: adjust if you really want \"last 10 years\")\n",
    "START_DATE = \"1998-01-01\"\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# daily variables as comma-joined string (safe)\n",
    "daily_vars = \",\".join([\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"precipitation_sum\",\n",
    "    \"rain_sum\",\n",
    "    \"sunshine_duration\"\n",
    "])\n",
    "\n",
    "def daterange_year_chunks(start_date_str, end_date_str):\n",
    "    start = datetime.fromisoformat(start_date_str)\n",
    "    end = datetime.fromisoformat(end_date_str)\n",
    "    cur = start\n",
    "    while cur < end:\n",
    "        # chunk by one calendar year\n",
    "        chunk_end = datetime(cur.year, 12, 31)\n",
    "        if chunk_end > end:\n",
    "            chunk_end = end\n",
    "        yield cur.strftime(\"%Y-%m-%d\"), chunk_end.strftime(\"%Y-%m-%d\")\n",
    "        cur = chunk_end + timedelta(days=1)\n",
    "\n",
    "rows = []\n",
    "for chunk_start, chunk_end in daterange_year_chunks(START_DATE, END_DATE):\n",
    "    params = {\n",
    "        \"latitude\": LATITUDE,\n",
    "        \"longitude\": LONGITUDE,\n",
    "        \"start_date\": chunk_start,\n",
    "        \"end_date\": chunk_end,\n",
    "        \"daily\": daily_vars,\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "    # simple retry/backoff\n",
    "    for attempt in range(4):\n",
    "        try:\n",
    "            r = requests.get(API_URL, params=params, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            payload = r.json()\n",
    "            if 'daily' not in payload:\n",
    "                raise ValueError(\"No 'daily' in API response: \" + str(payload)[:200])\n",
    "            d = payload['daily']\n",
    "            # map fields safely; check presence\n",
    "            needed = ['time', 'temperature_2m_max', 'temperature_2m_min', 'precipitation_sum', 'rain_sum', 'sunshine_duration']\n",
    "            for key in needed:\n",
    "                if key not in d:\n",
    "                    raise KeyError(f\"Missing key in daily: {key}\")\n",
    "            for i, dt in enumerate(d['time']):\n",
    "                rows.append({\n",
    "                    'date': dt,\n",
    "                    'temp_max_C': d['temperature_2m_max'][i],\n",
    "                    'temp_min_C': d['temperature_2m_min'][i],\n",
    "                    'precip_mm': d['precipitation_sum'][i],\n",
    "                    'rain_mm': d['rain_sum'][i],\n",
    "                    'sunshine_s': d['sunshine_duration'][i]\n",
    "                })\n",
    "            time.sleep(0.2)  # be polite\n",
    "            break\n",
    "        except (requests.RequestException, ValueError, KeyError) as e:\n",
    "            wait = 2 ** attempt\n",
    "            print(f\"Attempt {attempt+1} failed for {chunk_start} to {chunk_end}: {e}. Retrying in {wait}s.\")\n",
    "            time.sleep(wait)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Failed to fetch data for {chunk_start}..{chunk_end}\")\n",
    "\n",
    "# build DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "# convert types and compute derived columns\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "df['sunshine_h'] = df['sunshine_s'] / 3600.0\n",
    "df = df.drop(columns=['sunshine_s'])\n",
    "\n",
    "# save\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved {len(df)} daily rows to {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd4c91ed-d72f-4f81-ad43-bf29aa1f1ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 records to data/raw\\farm_records_simulated.csv\n",
      "   field_id   crop variety soil_type planting_date harvest_date  \\\n",
      "0       185  Maize       B      clay    2021-11-16   2022-04-03   \n",
      "1       138  Paddy       C      clay    2018-06-14   2018-10-14   \n",
      "2       164  Jowar       A      loam    2008-06-25   2008-11-07   \n",
      "3        46  Paddy       C      clay    2010-10-28   2011-03-10   \n",
      "4       122  Paddy       B     sandy    2015-11-07   2016-03-26   \n",
      "\n",
      "   fertilizer_kg_ha  pesticide_l_ha  yield_kg_ha  \n",
      "0            192.18           43.10      4835.92  \n",
      "1            176.73           43.03      5877.93  \n",
      "2             60.87           32.08      3182.76  \n",
      "3             94.32           11.61      5705.05  \n",
      "4            150.60            0.91      4580.22  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(42)  # reproducible\n",
    "RAW_DATA_PATH = 'data/raw'\n",
    "os.makedirs(RAW_DATA_PATH, exist_ok=True)\n",
    "OUTPUT_FILE = os.path.join(RAW_DATA_PATH, 'farm_records_simulated.csv')\n",
    "\n",
    "N_RECORDS_PER_CROP = 2500\n",
    "CROPS = ['Jowar', 'Paddy', 'Maize', 'Cotton']\n",
    "TOTAL_RECORDS = N_RECORDS_PER_CROP * len(CROPS)\n",
    "\n",
    "SIM_START_DATE = datetime(1998, 1, 1)\n",
    "SIM_END_DATE = datetime(2024, 1, 1)\n",
    "DATE_RANGE_DAYS = (SIM_END_DATE - SIM_START_DATE).days\n",
    "\n",
    "crop_list = np.repeat(CROPS, N_RECORDS_PER_CROP)\n",
    "random_days = np.random.randint(0, DATE_RANGE_DAYS, TOTAL_RECORDS)\n",
    "planting_dates = [SIM_START_DATE + timedelta(days=int(d)) for d in random_days]\n",
    "growth_days = np.random.randint(90, 151, TOTAL_RECORDS)\n",
    "harvest_dates = [pd + timedelta(days=int(gd)) for pd, gd in zip(planting_dates, growth_days)]\n",
    "\n",
    "fertilizer = np.random.uniform(50, 200, TOTAL_RECORDS).round(2)\n",
    "pesticide_l_ha = np.random.uniform(0, 50, TOTAL_RECORDS).round(2)  # new pesticide in L/ha\n",
    "\n",
    "# extra categorical features\n",
    "soil_types = ['clay', 'sandy', 'loam']\n",
    "varieties = ['A', 'B', 'C']\n",
    "field_ids = np.random.randint(1, 200, TOTAL_RECORDS)  # repeat fields across seasons\n",
    "\n",
    "base_yields = {'Jowar': 3000, 'Paddy': 6000, 'Maize': 5000, 'Cotton': 2500}\n",
    "\n",
    "def generate_yield(crop, fert, pest_l, soil):\n",
    "    base = base_yields[crop]\n",
    "    # crop-specific sensitivities\n",
    "    fert_eff = {'Jowar': 3.0, 'Paddy': 4.0, 'Maize': 4.5, 'Cotton': 2.5}[crop]\n",
    "    pest_eff = {'Jowar': 2.0, 'Paddy': 1.5, 'Maize': 2.2, 'Cotton': 1.0}[crop]\n",
    "    soil_adj = {'clay': -100, 'sandy': -150, 'loam': 50}[soil]\n",
    "    noise = np.random.normal(0, base * 0.12)\n",
    "    # treat pesticide in L/ha, center at 10 L/ha in sensitivity formula\n",
    "    y = base + fert_eff * (fert - 125) + pest_eff * (pest_l - 10) + soil_adj + noise\n",
    "    return round(max(0.0, y), 2)\n",
    "\n",
    "soil_choice = np.random.choice(soil_types, TOTAL_RECORDS)\n",
    "variety_choice = np.random.choice(varieties, TOTAL_RECORDS)\n",
    "\n",
    "yield_data = [generate_yield(c, f, p, s) for c, f, p, s in zip(crop_list, fertilizer, pesticide_l_ha, soil_choice)]\n",
    "\n",
    "df_simulated = pd.DataFrame({\n",
    "    'field_id': field_ids,\n",
    "    'crop': crop_list,\n",
    "    'variety': variety_choice,\n",
    "    'soil_type': soil_choice,\n",
    "    'planting_date': planting_dates,\n",
    "    'harvest_date': harvest_dates,\n",
    "    'fertilizer_kg_ha': fertilizer,\n",
    "    'pesticide_l_ha': pesticide_l_ha,\n",
    "    'yield_kg_ha': yield_data\n",
    "})\n",
    "\n",
    "df_simulated = df_simulated.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_simulated.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Saved {len(df_simulated)} records to {OUTPUT_FILE}\")\n",
    "print(df_simulated.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a76bf3-3d03-4de2-932d-68fbd482f3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
