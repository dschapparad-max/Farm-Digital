{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3deffc9b-becf-40ac-979a-28b8b16f8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training & Validation for: Jowar ===\n",
      "Saved validation CSV: models\\validation_reports\\jowar_validation.csv (500 rows)\n",
      "Saved scatter plot: models\\validation_reports\\jowar_true_vs_pred.png\n",
      "Saved metrics JSON: models\\validation_reports\\jowar_metrics.json\n",
      "Saved model and metadata to: models\\jowar_model.joblib and models\\jowar_model.joblib.meta.json\n",
      "\n",
      "=== Training & Validation for: Paddy ===\n",
      "Saved validation CSV: models\\validation_reports\\paddy_validation.csv (500 rows)\n",
      "Saved scatter plot: models\\validation_reports\\paddy_true_vs_pred.png\n",
      "Saved metrics JSON: models\\validation_reports\\paddy_metrics.json\n",
      "Saved model and metadata to: models\\paddy_model.joblib and models\\paddy_model.joblib.meta.json\n",
      "\n",
      "=== Training & Validation for: Maize ===\n",
      "Saved validation CSV: models\\validation_reports\\maize_validation.csv (500 rows)\n",
      "Saved scatter plot: models\\validation_reports\\maize_true_vs_pred.png\n",
      "Saved metrics JSON: models\\validation_reports\\maize_metrics.json\n",
      "Saved model and metadata to: models\\maize_model.joblib and models\\maize_model.joblib.meta.json\n",
      "\n",
      "=== Training & Validation for: Cotton ===\n",
      "Saved validation CSV: models\\validation_reports\\cotton_validation.csv (500 rows)\n",
      "Saved scatter plot: models\\validation_reports\\cotton_true_vs_pred.png\n",
      "Saved metrics JSON: models\\validation_reports\\cotton_metrics.json\n",
      "Saved model and metadata to: models\\cotton_model.joblib and models\\cotton_model.joblib.meta.json\n",
      "\n",
      "All training + validation reports complete.\n"
     ]
    }
   ],
   "source": [
    "# File: models/train_models.py\n",
    "# Updated: Adds detailed validation reporting (MAE, RMSE, R2, 95% PI, coverage)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Paths and config\n",
    "# ---------------------------\n",
    "RAW_PROCESSED = 'data/processed'\n",
    "MODELS_DIR = 'models'\n",
    "VALIDATION_DIR = os.path.join(MODELS_DIR, 'validation_reports')\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(VALIDATION_DIR, exist_ok=True)\n",
    "\n",
    "CROPS = ['Jowar', 'Paddy', 'Maize', 'Cotton']\n",
    "\n",
    "FEATURES = [\n",
    "    'fertilizer_kg_ha',\n",
    "    'irrigation_m3_ha',\n",
    "    'total_precip_mm',\n",
    "    'avg_temp_max_C',\n",
    "    'total_sunshine_h'\n",
    "]\n",
    "\n",
    "TARGET = 'yield_kg_ha'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Helper: save JSON\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(obj, f, indent=4)\n",
    "\n",
    "# ---------------------------\n",
    "# Training + Validation Loop\n",
    "# ---------------------------\n",
    "for crop in CROPS:\n",
    "    print(f\"\\n=== Training & Validation for: {crop} ===\")\n",
    "\n",
    "    csv_path = os.path.join(RAW_PROCESSED, f\"{crop.lower()}_model_data.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Skipping {crop}: {csv_path} not found\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if len(df) < 10:\n",
    "        print(f\"Skipping {crop}: not enough rows ({len(df)})\")\n",
    "        continue\n",
    "\n",
    "    X = df[FEATURES].values\n",
    "    y = df[TARGET].values\n",
    "\n",
    "    # Split: use a hold-out test set for validation reporting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Basic metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Estimate uncertainty from trees (std across estimators)\n",
    "    y_pred_tree_matrix = None\n",
    "    pred_std = None\n",
    "    if hasattr(model, 'estimators_') and len(model.estimators_) > 1:\n",
    "        try:\n",
    "            # each tree's predictions on X_test -> shape (n_trees, n_samples)\n",
    "            y_pred_tree_matrix = np.vstack([t.predict(X_test) for t in model.estimators_])\n",
    "            pred_std = np.std(y_pred_tree_matrix, axis=0, ddof=0)  # per-sample std\n",
    "            # 95% prediction interval via mean +/- 1.96*std\n",
    "            lower_95 = y_pred - 1.96 * pred_std\n",
    "            upper_95 = y_pred + 1.96 * pred_std\n",
    "            # coverage: fraction of true y inside the interval\n",
    "            coverage = float(np.mean((y_test >= lower_95) & (y_test <= upper_95)))\n",
    "        except Exception as e:\n",
    "            print(\"Warning: could not compute tree-based std:\", e)\n",
    "            pred_std = np.full_like(y_pred, np.nan)\n",
    "            lower_95 = np.full_like(y_pred, np.nan)\n",
    "            upper_95 = np.full_like(y_pred, np.nan)\n",
    "            coverage = None\n",
    "    else:\n",
    "        pred_std = np.full_like(y_pred, np.nan)\n",
    "        lower_95 = np.full_like(y_pred, np.nan)\n",
    "        upper_95 = np.full_like(y_pred, np.nan)\n",
    "        coverage = None\n",
    "\n",
    "    # Build validation dataframe and save\n",
    "    val_df = pd.DataFrame({\n",
    "        'y_true': y_test,\n",
    "        'y_pred_mean': y_pred,\n",
    "        'y_pred_std': pred_std,\n",
    "        'lower_95': lower_95,\n",
    "        'upper_95': upper_95,\n",
    "        'residual': y_test - y_pred\n",
    "    })\n",
    "\n",
    "    val_csv_path = os.path.join(VALIDATION_DIR, f\"{crop.lower()}_validation.csv\")\n",
    "    val_df.to_csv(val_csv_path, index=False)\n",
    "    print(f\"Saved validation CSV: {val_csv_path} ({len(val_df)} rows)\")\n",
    "\n",
    "    # Save simple scatter plot (y_true vs y_pred)\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.scatter(y_test, y_pred, alpha=0.6, s=10)\n",
    "        lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
    "        ax.plot(lims, lims, 'r--', linewidth=1)  # identity line\n",
    "        ax.set_xlabel('y_true (kg/ha)')\n",
    "        ax.set_ylabel('y_pred (kg/ha)')\n",
    "        ax.set_title(f\"{crop} - True vs Pred (MAE={mae:.2f})\")\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(VALIDATION_DIR, f\"{crop.lower()}_true_vs_pred.png\")\n",
    "        fig.savefig(plot_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved scatter plot: {plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not save plot:\", e)\n",
    "\n",
    "    # Save metrics JSON\n",
    "    metrics = {\n",
    "        'crop': crop,\n",
    "        'n_train': int(len(X_train)),\n",
    "        'n_test': int(len(X_test)),\n",
    "        'mae': float(mae),\n",
    "        'rmse': float(rmse),\n",
    "        'r2': float(r2),\n",
    "        'prediction_interval_95_coverage': coverage if coverage is not None else None\n",
    "    }\n",
    "    metrics_path = os.path.join(VALIDATION_DIR, f\"{crop.lower()}_metrics.json\")\n",
    "    save_json(metrics, metrics_path)\n",
    "    print(f\"Saved metrics JSON: {metrics_path}\")\n",
    "\n",
    "    # Save model + metadata (embed metrics into metadata)\n",
    "    model_path = os.path.join(MODELS_DIR, f\"{crop.lower()}_model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    metadata = {\n",
    "        \"features\": FEATURES,\n",
    "        \"units\": {\n",
    "            \"fertilizer_kg_ha\": \"kg/ha\",\n",
    "            \"irrigation_m3_ha\": \"m3/ha\",\n",
    "            \"total_precip_mm\": \"mm\",\n",
    "            \"avg_temp_max_C\": \"degC\",\n",
    "            \"total_sunshine_h\": \"hours\"\n",
    "        },\n",
    "        \"trained_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"validation_metrics\": metrics\n",
    "    }\n",
    "    meta_file = model_path + '.meta.json'\n",
    "    save_json(metadata, meta_file)\n",
    "    print(f\"Saved model and metadata to: {model_path} and {meta_file}\")\n",
    "\n",
    "print(\"\\nAll training + validation reports complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8850b6a3-fe97-439a-94ed-f713694e2d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.50.0-cp312-cp312-win_amd64.whl.metadata (25 kB)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: scipy in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\documents\\ai lab\\lib\\site-packages (from shap) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\documents\\ai lab\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\documents\\ai lab\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\documents\\ai lab\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\documents\\ai lab\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.50.0-cp312-cp312-win_amd64.whl (549 kB)\n",
      "   ---------------------------------------- 0.0/549.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 549.3/549.3 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 7.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/15.6 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.6 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.8/15.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, numpy, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.0.2 shap-0.50.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a00159-f6a7-4ebe-9af3-f29eb67c4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.50.0-cp312-cp312-win_amd64.whl.metadata (25 kB)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: scipy in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\documents\\ai lab\\lib\\site-packages (from shap) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\documents\\ai lab\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\documents\\ai lab\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\documents\\ai lab\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\documents\\ai lab\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.50.0-cp312-cp312-win_amd64.whl (549 kB)\n",
      "   ---------------------------------------- 0.0/549.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 549.3/549.3 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 7.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/15.6 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.6 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.8/15.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, numpy, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.0.2 shap-0.50.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634607b1-4a80-4ed5-a32f-625f747f07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.50.0-cp312-cp312-win_amd64.whl.metadata (25 kB)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: scipy in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\documents\\ai lab\\lib\\site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\documents\\ai lab\\lib\\site-packages (from shap) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\documents\\ai lab\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\documents\\ai lab\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\documents\\ai lab\\lib\\site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\documents\\ai lab\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Collecting numpy>=2 (from shap)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in c:\\documents\\ai lab\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\documents\\ai lab\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\documents\\ai lab\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\documents\\ai lab\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.50.0-cp312-cp312-win_amd64.whl (549 kB)\n",
      "   ---------------------------------------- 0.0/549.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 549.3/549.3 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/15.6 MB 7.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.1/15.6 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.6 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.8/15.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.6 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: slicer, numpy, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.0.2 shap-0.50.0 slicer-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Documents\\AI lab\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
